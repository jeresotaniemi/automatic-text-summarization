{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f83328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sumy rouge-score nltk lxml_html_clean spacy matplotlib scikit-learn pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371ae305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and global variables\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import spacy\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# python -m spacy download en_core_web_sm <-- Run this command in terminal if the model is not already downloaded\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize language for stemmer and the number of most important sentences returned\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 3\n",
    "\n",
    "# **IMPORTANT Note**: Since we are using Sumy package instead of the original PyTLDR, there is no direct counterpart for Relevance sentence scoring. We use the closest equivalent LexRank which also uses cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7a428",
   "metadata": {},
   "source": [
    "### Task 1: Three summarization algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text document\n",
    "example_document = \"\"\"\n",
    "Natural language processing and text mining is a course in Master's degree program in the Univeristy of Oulu.\n",
    "Video games are good for passing time efficiently.\n",
    "University of Oulu has multiple restaurants which are cheap and offer healthy food.\n",
    "Multiple different courses require experience on programming languages.\n",
    "Oulu is known for many technology companies such as Oura and Fingersoft.\n",
    "\"\"\"\n",
    "parser = PlaintextParser.from_string(example_document, Tokenizer(LANGUAGE))\n",
    "\n",
    "print(\"--- Top 3 Most Important Sentences by Each Algorithm (Stemming and Stopword Removal) ---\")\n",
    "# TextRank summarization\n",
    "textrank_summarizer = TextRankSummarizer(Stemmer(LANGUAGE))\n",
    "textrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "print(\"\\nTextRank Summary:\")\n",
    "for sentence in textrank_summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(\"-\", sentence)\n",
    "\n",
    "# LSA summarization\n",
    "lsa_summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "lsa_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "print(\"\\nLSA Summary:\")\n",
    "for sentence in lsa_summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(\"-\", sentence)\n",
    "\n",
    "# LexRank summarization\n",
    "lexrank_summarizer = LexRankSummarizer(Stemmer(LANGUAGE))\n",
    "lexrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "print(\"\\nLexRank Summary:\")\n",
    "for sentence in lexrank_summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(\"-\", sentence)\n",
    "\n",
    "print(\"\\n--- Top 3 Most Important Sentences by Each Algorithm (NO Stemming and Stopword Revomal) ---\")\n",
    "# TextRank summarization\n",
    "textrank_summarizer = TextRankSummarizer()\n",
    "print(\"\\nTextRank Summary:\")\n",
    "for sentence in textrank_summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(\"-\", sentence)\n",
    "\n",
    "# LSA summarization\n",
    "lsa_summarizer = LsaSummarizer()\n",
    "print(\"\\nLSA Summary:\")\n",
    "for sentence in lsa_summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(\"-\", sentence)\n",
    "\n",
    "# LexRank summarization\n",
    "lexrank_summarizer = LexRankSummarizer()\n",
    "print(\"\\nLexRank Summary:\")\n",
    "for sentence in lexrank_summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(\"-\", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fdece2",
   "metadata": {},
   "source": [
    "### Task 2: Text summarizer GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The summarizer GUI will open in a new window and this cell will run as long as the window is open.\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, scrolledtext, messagebox\n",
    "\n",
    "\n",
    "# Helper function for text summarization\n",
    "def summarize_text(source, is_url=False):\n",
    "    try:\n",
    "        if is_url:\n",
    "            parser = HtmlParser.from_url(source, Tokenizer(LANGUAGE))\n",
    "        else:\n",
    "            parser = PlaintextParser.from_file(source, Tokenizer(LANGUAGE))\n",
    "\n",
    "        # Initialize summarizers, use stemming and stop word removal\n",
    "        textrank = TextRankSummarizer(Stemmer(LANGUAGE))\n",
    "        textrank.stop_words = get_stop_words(LANGUAGE)\n",
    "        lsa = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "        lsa.stop_words = get_stop_words(LANGUAGE)\n",
    "        lexrank = LexRankSummarizer(Stemmer(LANGUAGE))\n",
    "        lexrank.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "        # Create dictionary for summarizer outputs\n",
    "        summaries = {\n",
    "            \"TextRank\": \"\\n\\n \".join(\n",
    "                f\" - {s}\" for s in textrank(parser.document, SENTENCES_COUNT)\n",
    "            ),\n",
    "            \"LSA\": \"\\n\\n\".join(f\" - {s}\" for s in lsa(parser.document, SENTENCES_COUNT)),\n",
    "            \"LexRank\": \"\\n\\n\".join(\n",
    "                f\" - {s}\" for s in lexrank(parser.document, SENTENCES_COUNT)\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        return summaries\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter a URL or choose a file\")\n",
    "        print(\"Error: \", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "# Helper function for browsing a file\n",
    "def browse_file():\n",
    "    filename = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\n",
    "    entry_source.delete(0, tk.END)\n",
    "    entry_source.insert(0, filename)\n",
    "\n",
    "\n",
    "# Helper function for running summary\n",
    "def run_summary():\n",
    "    source = entry_source.get().strip()\n",
    "    if not source:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter a URL or choose a file\")\n",
    "        return None\n",
    "\n",
    "    is_url = source.startswith(\"http\")\n",
    "    summaries = summarize_text(source, is_url)\n",
    "\n",
    "    # Delete old summaries and add new ones (if summarizers are run multiple times)\n",
    "    if summaries:\n",
    "        text_textrank.delete(1.0, tk.END)\n",
    "        text_lsa.delete(1.0, tk.END)\n",
    "        text_lexrank.delete(1.0, tk.END)\n",
    "        text_textrank.insert(tk.END, summaries[\"TextRank\"])\n",
    "        text_lsa.insert(tk.END, summaries[\"LSA\"])\n",
    "        text_lexrank.insert(tk.END, summaries[\"LexRank\"])\n",
    "\n",
    "\n",
    "# GUI setup using tkinter library\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Summarizer\")\n",
    "root.geometry(\"1200x700\")\n",
    "\n",
    "frame_top = tk.Frame(root)\n",
    "frame_top.pack(pady=10)\n",
    "\n",
    "tk.Label(\n",
    "    frame_top, text=\"Enter URL or choose a file to get 3 most important sentences:\"\n",
    ").pack(anchor=\"w\", padx=5)\n",
    "entry_source = tk.Entry(frame_top, width=70)\n",
    "entry_source.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "btn_browse = tk.Button(frame_top, text=\"Browse File\", command=browse_file)\n",
    "btn_browse.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "btn_summarize = tk.Button(frame_top, text=\"Summarize\", command=run_summary)\n",
    "btn_summarize.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "# --Text areas for summaries--\n",
    "frame_texts = tk.Frame(root)\n",
    "frame_texts.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# TextRank section\n",
    "frame_textrank = tk.Frame(frame_texts)\n",
    "frame_textrank.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "\n",
    "tk.Label(frame_textrank, text=\"TextRank Summary:\").pack(anchor=\"n\", pady=5)\n",
    "text_textrank = scrolledtext.ScrolledText(frame_textrank, wrap=tk.WORD, width=40)\n",
    "text_textrank.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# LSA section\n",
    "frame_lsa = tk.Frame(frame_texts)\n",
    "frame_lsa.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "\n",
    "tk.Label(frame_lsa, text=\"LSA Summary:\").pack(pady=5)\n",
    "text_lsa = scrolledtext.ScrolledText(frame_lsa, wrap=tk.WORD, width=40)\n",
    "text_lsa.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# LexRank section\n",
    "frame_lexrank = tk.Frame(frame_texts)\n",
    "frame_lexrank.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "\n",
    "tk.Label(frame_lexrank, text=\"LexRank Summary:\").pack(pady=5)\n",
    "text_lexrank = scrolledtext.ScrolledText(frame_lexrank, wrap=tk.WORD, width=40)\n",
    "text_lexrank.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "print(\"Text Summarizer GUI is running on a separate window!\")\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e658c8b",
   "metadata": {},
   "source": [
    "### Task 3: Summarizer Performance on CNN/Dailymail Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5007ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "STEM = True\n",
    "STOP_WORD_REMOVAL = True\n",
    "TOP_SUMMARIES_COUNT = 5\n",
    "\n",
    "\n",
    "def extract_doc_and_abstraction(data):\n",
    "    extracted_data = []\n",
    "    data_idx = -1\n",
    "    extracted_word_count = 0\n",
    "    for idx, line in enumerate(data):\n",
    "        if line == \"Document\\n\":\n",
    "            data_idx += 1\n",
    "            extracted_data.append({\"document\": data[idx + 1].rstrip(\"\\n\")})\n",
    "            extracted_word_count += len(extracted_data[data_idx][\"document\"].split())\n",
    "            continue\n",
    "        if line.startswith(\"Facet-\"):\n",
    "            abstraction = line.rstrip(\"\\n\").split(\" \", 1)[1]\n",
    "            if \"abstractions\" not in extracted_data[data_idx]:\n",
    "                extracted_data[data_idx][\"abstractions\"] = []\n",
    "            extracted_data[data_idx][\"abstractions\"].append(abstraction)\n",
    "\n",
    "    print(f\"Total extracted samples: {len(extracted_data)}\")\n",
    "    print(f\"Total extracted words in documents: {extracted_word_count}\")\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def rouge_evaluation(reference, hypothesis, rouge_type):\n",
    "    scorer = rouge_scorer.RougeScorer([rouge_type], use_stemmer=True)\n",
    "    score = scorer.score(reference, hypothesis)[rouge_type]\n",
    "    return score\n",
    "\n",
    "\n",
    "with open(\"Data/Cnn&Dailymail/low_abstraction.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    data = extract_doc_and_abstraction(f.readlines())\n",
    "\n",
    "\n",
    "def get_max_rouge_scores(abstractions, summary, rouge_type):\n",
    "    scores = [rouge_evaluation(abst, str(summary), rouge_type) for abst in abstractions]\n",
    "    precision = np.max([score.precision for score in scores])\n",
    "    recall = np.max([score.recall for score in scores])\n",
    "    fmeasure = np.max([score.fmeasure for score in scores])\n",
    "    return precision, recall, fmeasure\n",
    "\n",
    "\n",
    "if STEM:\n",
    "    textrank_summarizer = TextRankSummarizer(Stemmer(LANGUAGE))\n",
    "    lsa_summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "    lexrank_summarizer = LexRankSummarizer(Stemmer(LANGUAGE))\n",
    "else:\n",
    "    textrank_summarizer = TextRankSummarizer()\n",
    "    lsa_summarizer = LsaSummarizer()\n",
    "    lexrank_summarizer = LexRankSummarizer()\n",
    "\n",
    "if STOP_WORD_REMOVAL:\n",
    "    textrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "    lsa_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "    lexrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "summarizers = [\"TextRank\", \"LSA\", \"LexRank\"]\n",
    "rouge_types = [\"rouge2\", \"rouge3\"]\n",
    "metrics = [\"precision\", \"recall\", \"fmeasure\"]\n",
    "\n",
    "\n",
    "doc_scores = []\n",
    "summary_keys = [f\"summary{i + 1}\" for i in range(TOP_SUMMARIES_COUNT)]\n",
    "score_template = {\n",
    "    f\"{summary_key}\": {\n",
    "        f\"{summarizer}\": {\n",
    "            f\"{rouge_type}\": {metric: 0 for metric in metrics}\n",
    "            for rouge_type in rouge_types\n",
    "        }\n",
    "        for summarizer in summarizers\n",
    "    }\n",
    "    for summary_key in summary_keys\n",
    "}\n",
    "\n",
    "for doc in data:\n",
    "    scores = deepcopy(score_template)\n",
    "    document = doc[\"document\"]\n",
    "    abstractions = doc[\"abstractions\"]\n",
    "    parser = PlaintextParser.from_string(document, Tokenizer(LANGUAGE))\n",
    "\n",
    "    summaries = {f\"{summarizer}\": [] for summarizer in summarizers}\n",
    "    summaries[\"TextRank\"] = textrank_summarizer(parser.document, TOP_SUMMARIES_COUNT)\n",
    "    summaries[\"LSA\"] = lsa_summarizer(parser.document, TOP_SUMMARIES_COUNT)\n",
    "    summaries[\"LexRank\"] = lexrank_summarizer(parser.document, TOP_SUMMARIES_COUNT)\n",
    "\n",
    "    for summary_idx in range(TOP_SUMMARIES_COUNT):\n",
    "        for summarizer in summarizers:\n",
    "            for rouge_type in rouge_types:\n",
    "                summary_key = f\"summary{summary_idx + 1}\"\n",
    "                precision, recall, fmeasure = get_max_rouge_scores(\n",
    "                    abstractions, summaries[summarizer][summary_idx], rouge_type\n",
    "                )\n",
    "                scores[summary_key][summarizer][rouge_type][\"precision\"] = precision\n",
    "                scores[summary_key][summarizer][rouge_type][\"recall\"] = recall\n",
    "                scores[summary_key][summarizer][rouge_type][\"fmeasure\"] = fmeasure\n",
    "                if fmeasure > 1.0:  # Set threshold to smaller value to see outputs\n",
    "                    print(\n",
    "                        f\"{rouge_type} {summarizer} {summary_key} fmeasure: {fmeasure:.3f}\\n\"\n",
    "                        f\"Abstractions: {json.dumps(abstractions, indent=2)}\\n\"\n",
    "                        f\"Summary: {json.dumps(str(summaries[summarizer][summary_idx]), indent=2)}\"\n",
    "                    )\n",
    "\n",
    "    doc_scores.append(scores)\n",
    "\n",
    "\n",
    "avg_scores = deepcopy(score_template)\n",
    "\n",
    "for doc_score in doc_scores:\n",
    "    for summary_key in summary_keys:\n",
    "        for summarizer in summarizers:\n",
    "            for rouge_type in rouge_types:\n",
    "                avg_scores[summary_key][summarizer][rouge_type][\"precision\"] += (\n",
    "                    doc_score[summary_key][summarizer][rouge_type][\"precision\"]\n",
    "                    / len(doc_scores)\n",
    "                )\n",
    "                avg_scores[summary_key][summarizer][rouge_type][\"recall\"] += doc_score[\n",
    "                    summary_key\n",
    "                ][summarizer][rouge_type][\"recall\"] / len(doc_scores)\n",
    "                avg_scores[summary_key][summarizer][rouge_type][\"fmeasure\"] += (\n",
    "                    doc_score[summary_key][summarizer][rouge_type][\"fmeasure\"]\n",
    "                    / len(doc_scores)\n",
    "                )\n",
    "\n",
    "\n",
    "def plot_rouge_scores(ax, rouge_type, metric):\n",
    "    summary_indices = range(1, TOP_SUMMARIES_COUNT + 1)\n",
    "    ax.set_title(f\"Average {rouge_type.upper()} scores ({metric})\")\n",
    "    ax.set_xlabel(\"Summary Index\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_xticks(summary_indices)\n",
    "    for summarizer in summarizers:\n",
    "        scores = [\n",
    "            avg_scores[f\"summary{idx}\"][summarizer][rouge_type][metric]\n",
    "            for idx in summary_indices\n",
    "        ]\n",
    "        ax.plot(summary_indices, scores, marker=\"o\", label=summarizer)\n",
    "        if metric == \"fmeasure\":\n",
    "            print(f\"{rouge_type} fmeasure top score for {summarizer}: {scores[0]:.3f}\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "# Plot the average ROUGE scores\n",
    "_, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(21, 12))\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "for i, (rouge_type, metric) in enumerate(\n",
    "    [\n",
    "        (\"rouge2\", \"fmeasure\"),\n",
    "        (\"rouge2\", \"precision\"),\n",
    "        (\"rouge2\", \"recall\"),\n",
    "        (\"rouge3\", \"fmeasure\"),\n",
    "        (\"rouge3\", \"precision\"),\n",
    "        (\"rouge3\", \"recall\"),\n",
    "    ]\n",
    "):\n",
    "    plot_rouge_scores(axes[i], rouge_type, metric)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdd889",
   "metadata": {},
   "source": [
    "### Task 4: Named Entity Performance Enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NEW_SENTENCES = 3\n",
    "\n",
    "\n",
    "def extract_doc_and_abstraction(data):\n",
    "    extracted_data = []\n",
    "    data_idx = -1\n",
    "    for idx, line in enumerate(data):\n",
    "        if line == \"Document\\n\":\n",
    "            data_idx += 1\n",
    "            extracted_data.append({\"document\": data[idx + 1].rstrip(\"\\n\")})\n",
    "            continue\n",
    "        if line.startswith(\"Facet-\"):\n",
    "            abstraction = line.rstrip(\"\\n\").split(\" \", 1)[1]\n",
    "            if \"abstractions\" not in extracted_data[data_idx]:\n",
    "                extracted_data[data_idx][\"abstractions\"] = []\n",
    "            extracted_data[data_idx][\"abstractions\"].append(abstraction)\n",
    "    print(f\"Total extracted samples: {len(extracted_data)}\")\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "with open(\"Data/Cnn&Dailymail/low_abstraction.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    data = extract_doc_and_abstraction(f.readlines())\n",
    "\n",
    "\n",
    "def rouge_evaluation(reference, hypothesis, rouge_type):\n",
    "    scorer = rouge_scorer.RougeScorer([rouge_type], use_stemmer=True)\n",
    "    score = scorer.score(reference, hypothesis)[rouge_type]\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_max_rouge_scores(abstractions, summary, rouge_type):\n",
    "    scores = [rouge_evaluation(abst, str(summary), rouge_type) for abst in abstractions]\n",
    "    precision = np.max([score.precision for score in scores])\n",
    "    recall = np.max([score.recall for score in scores])\n",
    "    fmeasure = np.max([score.fmeasure for score in scores])\n",
    "    return precision, recall, fmeasure\n",
    "\n",
    "\n",
    "def add_sents_containing_named_entities(summary, document, max_new_sentences):\n",
    "    if max_new_sentences == 0:\n",
    "        return [str(summary)]\n",
    "\n",
    "    summary_doc = nlp(str(summary))\n",
    "    summary_entities = {\n",
    "        ent.text for ent in summary_doc.ents if ent.label_ in (\"PERSON\", \"ORG\")\n",
    "    }\n",
    "\n",
    "    if not summary_entities:\n",
    "        return [str(summary)]\n",
    "\n",
    "    document_sents = Tokenizer(LANGUAGE).to_sentences(document)\n",
    "\n",
    "    summary_text = str(summary)\n",
    "    candidates = []\n",
    "\n",
    "    for sent in document_sents:\n",
    "        # Skip if it's the summary sentence itself\n",
    "        if sent == summary_text:\n",
    "            continue\n",
    "\n",
    "        sent_doc = nlp(sent)\n",
    "        sent_entities = {\n",
    "            ent.text for ent in sent_doc.ents if ent.label_ in (\"PERSON\", \"ORG\")\n",
    "        }\n",
    "\n",
    "        overlap = summary_entities & sent_entities\n",
    "\n",
    "        if overlap:\n",
    "            candidates.append((sent, len(overlap)))\n",
    "\n",
    "    # Sort by number of matching entities (descending)\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    if candidates and candidates[0][1] > 2:  # Change threshold to see more/less outputs\n",
    "        print(\"Good candidate found:\", candidates[0])\n",
    "        print(\"Summary text:\", summary_text)\n",
    "        print(\"Named entities in summary:\", summary_entities)\n",
    "\n",
    "    # Take top max_new_sentences\n",
    "    selected_sentences = [summary_text]\n",
    "    selected_sentences.extend(sent for sent, _ in candidates[:max_new_sentences])\n",
    "\n",
    "    return selected_sentences\n",
    "\n",
    "\n",
    "textrank_summarizer = TextRankSummarizer(Stemmer(LANGUAGE))\n",
    "textrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "lsa_summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "lsa_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "lexrank_summarizer = LexRankSummarizer(Stemmer(LANGUAGE))\n",
    "lexrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "summarizers = [\"TextRank\", \"LSA\", \"LexRank\"]\n",
    "rouge_types = [\"rouge2\", \"rouge3\"]\n",
    "metrics = [\"precision\", \"recall\", \"fmeasure\"]\n",
    "\n",
    "TOP_SUMMARIES_COUNT = 5\n",
    "\n",
    "doc_scores = []\n",
    "score_template = {\n",
    "    f\"{summarizer}\": {\n",
    "        f\"{rouge_type}\": {\n",
    "            metric: [-1 for _ in range(MAX_NEW_SENTENCES + 1)] for metric in metrics\n",
    "        }\n",
    "        for rouge_type in rouge_types\n",
    "    }\n",
    "    for summarizer in summarizers\n",
    "}\n",
    "\n",
    "for doc in data:\n",
    "    scores = deepcopy(score_template)\n",
    "    document = doc[\"document\"]\n",
    "    abstractions = doc[\"abstractions\"]\n",
    "    parser = PlaintextParser.from_string(document, Tokenizer(LANGUAGE))\n",
    "\n",
    "    summaries = {f\"{summarizer}\": [] for summarizer in summarizers}\n",
    "    summaries[\"TextRank\"] = textrank_summarizer(parser.document, TOP_SUMMARIES_COUNT)[0]\n",
    "    summaries[\"LSA\"] = lsa_summarizer(parser.document, TOP_SUMMARIES_COUNT)[0]\n",
    "    summaries[\"LexRank\"] = lexrank_summarizer(parser.document, TOP_SUMMARIES_COUNT)[0]\n",
    "\n",
    "    summaries[\"TextRank\"] = add_sents_containing_named_entities(\n",
    "        summaries[\"TextRank\"], document, MAX_NEW_SENTENCES\n",
    "    )\n",
    "    summaries[\"LSA\"] = add_sents_containing_named_entities(\n",
    "        summaries[\"LSA\"], document, MAX_NEW_SENTENCES\n",
    "    )\n",
    "    summaries[\"LexRank\"] = add_sents_containing_named_entities(\n",
    "        summaries[\"LexRank\"], document, MAX_NEW_SENTENCES\n",
    "    )\n",
    "\n",
    "    for summarizer in summarizers:\n",
    "        for rouge_type in rouge_types:\n",
    "            for i in range(len(summaries[summarizer])):\n",
    "                precision, recall, fmeasure = get_max_rouge_scores(\n",
    "                    abstractions, \" \".join(summaries[summarizer][: i + 1]), rouge_type\n",
    "                )\n",
    "                scores[summarizer][rouge_type][\"precision\"][i] = precision\n",
    "                scores[summarizer][rouge_type][\"recall\"][i] = recall\n",
    "                scores[summarizer][rouge_type][\"fmeasure\"][i] = fmeasure\n",
    "\n",
    "    doc_scores.append(scores)\n",
    "\n",
    "\n",
    "avg_scores = score_template = {\n",
    "    f\"{summarizer}\": {\n",
    "        f\"{rouge_type}\": {\n",
    "            metric: [[] for _ in range(MAX_NEW_SENTENCES + 1)] for metric in metrics\n",
    "        }\n",
    "        for rouge_type in rouge_types\n",
    "    }\n",
    "    for summarizer in summarizers\n",
    "}\n",
    "\n",
    "for doc_score in doc_scores:\n",
    "    for summarizer in summarizers:\n",
    "        for rouge_type in rouge_types:\n",
    "            for metric in metrics:\n",
    "                for i in range(MAX_NEW_SENTENCES + 1):\n",
    "                    if doc_score[summarizer][rouge_type][metric][i] >= 0:\n",
    "                        avg_scores[summarizer][rouge_type][metric][i].append(\n",
    "                            doc_score[summarizer][rouge_type][metric][i]\n",
    "                        )\n",
    "\n",
    "# Take averages\n",
    "for summarizer in summarizers:\n",
    "    for rouge_type in rouge_types:\n",
    "        for metric in metrics:\n",
    "            for i in range(MAX_NEW_SENTENCES + 1):\n",
    "                avg_scores[summarizer][rouge_type][metric][i] = np.mean(\n",
    "                    avg_scores[summarizer][rouge_type][metric][i]\n",
    "                )\n",
    "\n",
    "\n",
    "def plot_rouge_scores(ax, rouge_type):\n",
    "    \"\"\"Plot average ROUGE scores for the fmeasure metric.\n",
    "    On x-axis there is the number of added sentences containing named entities.\n",
    "    On y-axis there is the average ROUGE fmeasure score.\n",
    "    \"\"\"\n",
    "    x = np.arange(0, MAX_NEW_SENTENCES + 1)\n",
    "    x_ticks = [str(i) for i in range(0, MAX_NEW_SENTENCES + 1)]\n",
    "    ax.set_xticks(x, x_ticks)\n",
    "    for summarizer in summarizers:\n",
    "        y = avg_scores[summarizer][rouge_type][\"fmeasure\"]\n",
    "        ax.plot(\n",
    "            x,\n",
    "            y,\n",
    "            marker=\"o\",\n",
    "            label=summarizer,\n",
    "        )\n",
    "    ax.set_title(f\"Average {rouge_type.upper()} F1-Score\")\n",
    "    ax.set_xlabel(\"Number of Added Sentences Containing Named Entities\")\n",
    "    ax.set_ylabel(\"Average F1-Score\")\n",
    "\n",
    "    ax.legend(loc=\"upper right\", fontsize=10)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "\n",
    "# Plot the average ROUGE scores\n",
    "_, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for j, rouge_type in enumerate(rouge_types):\n",
    "    plot_rouge_scores(axes[j], rouge_type)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdee8c",
   "metadata": {},
   "source": [
    "### Task 6: Algorithm Performance on Opinosis Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f570ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rouge_score import rouge_scorer\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper function for text summarization\n",
    "def summarize_text(text, summarizer):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))\n",
    "    return \" \".join(str(s) for s in summarizer(parser.document, SENTENCES_COUNT))\n",
    "\n",
    "\n",
    "# Helper function for ROUGE evaluation\n",
    "def evaluate_rouge(system_summary, reference_summary):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    scores = scorer.score(reference_summary, system_summary)\n",
    "    return {k: v.fmeasure for k, v in scores.items()}\n",
    "\n",
    "\n",
    "# Setup summarizers (use stemming and stopword removal)\n",
    "summarizers = {\n",
    "    \"TextRank\": TextRankSummarizer(Stemmer(LANGUAGE)),\n",
    "    \"LSA\": LsaSummarizer(Stemmer(LANGUAGE)),\n",
    "    \"LexRank\": LexRankSummarizer(Stemmer(LANGUAGE)),\n",
    "}\n",
    "for s in summarizers.values():\n",
    "    s.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "# Loop through the opinosis dataset\n",
    "topics_path = \"Data/OpinosisDataset/topics\"\n",
    "summaries_path = \"Data/OpinosisDataset/summaries-gold\"\n",
    "\n",
    "result_list = {name: [] for name in summarizers}\n",
    "\n",
    "for topic_file in os.listdir(topics_path):\n",
    "    if not topic_file.endswith(\".txt.data\"):\n",
    "        continue\n",
    "\n",
    "    # Get the topic name from the file and construct paths for topics and gold summaries\n",
    "    topic_name = topic_file.replace(\"txt.data\", \"\")\n",
    "    topic_path = os.path.join(topics_path, topic_file)\n",
    "    summaries_dir = os.path.join(summaries_path, topic_name)\n",
    "\n",
    "    if not os.path.exists(summaries_dir):\n",
    "        continue\n",
    "\n",
    "    # Read all reviews for the topic (there are mixed encodings in the dataset)\n",
    "    try:\n",
    "        with open(topic_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(topic_path, \"r\", encoding=\"latin-1\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "    # Read all gold summaries for the topic with glob\n",
    "    summaries_paths = sorted(glob(os.path.join(summaries_dir, \"*.gold\")))\n",
    "    gold_summaries = []\n",
    "    for s in summaries_paths:\n",
    "        with open(s, \"r\", encoding=\"utf-8\") as summary_file:\n",
    "            gold_summaries.append(summary_file.read())\n",
    "\n",
    "    # Evaluate each summarizer\n",
    "    for name, summarizer in summarizers.items():\n",
    "        system_summary = summarize_text(text, summarizer)\n",
    "        all_rouge = []\n",
    "        for gold in gold_summaries:\n",
    "            all_rouge.append(evaluate_rouge(system_summary, gold))\n",
    "\n",
    "        # Compute average across all gold summaries\n",
    "        avg_rouge1 = sum(r[\"rouge1\"] for r in all_rouge) / len(all_rouge)\n",
    "        avg_rouge2 = sum(r[\"rouge2\"] for r in all_rouge) / len(all_rouge)\n",
    "        result_list[name].append({\"rouge1\": avg_rouge1, \"rouge2\": avg_rouge2})\n",
    "\n",
    "# Compute overall averages scores into a DataFrame\n",
    "avg_results = {}\n",
    "for name, scores in result_list.items():\n",
    "    avg_r1 = sum(s[\"rouge1\"] for s in scores) / len(scores)\n",
    "    avg_r2 = sum(s[\"rouge2\"] for s in scores) / len(scores)\n",
    "    avg_results[name] = {\"ROUGE-1\": avg_r1, \"ROUGE-2\": avg_r2}\n",
    "\n",
    "# Save the variables into a DataFrame where summarizers are as rows\n",
    "df = pd.DataFrame(avg_results).T\n",
    "print(\"--- Performance of TextRank, Latent Semantic and LexRank algorithms on Opinosis dataset in terms of Rouge-1 and Rouge-2 ---\")\n",
    "print(df.round(3))\n",
    "\n",
    "# Plot side-by-side bar chart\n",
    "algorithms = df.index\n",
    "rouge1 = df[\"ROUGE-1\"]\n",
    "rouge2 = df[\"ROUGE-2\"]\n",
    "\n",
    "x = np.arange(len(algorithms))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(x - width/2, rouge1, width, label=\"ROUGE-1\")\n",
    "ax.bar(x + width/2, rouge2, width, label=\"ROUGE-2\")\n",
    "\n",
    "ax.set_xlabel(\"Summarization Algorithm\")\n",
    "ax.set_ylabel(\"Average F1-Score\")\n",
    "ax.set_title(\"Performance Comparison on Opinosis Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithms)\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35baa863",
   "metadata": {},
   "source": [
    "### Task 7: Edmundson Summarizer Performance on Opinosis Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a204879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edmundson_summarize():\n",
    "    # Initialize Edmundson summarizer\n",
    "    # Has default weights: cue = 1, key = 0, title = 1, location = 1\n",
    "    summarizer = EdmundsonSummarizer(Stemmer(LANGUAGE))\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    # Set null words (irrelevant words)\n",
    "    summarizer.null_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    # Set custom bonus and stigma words\n",
    "    # For bonus words, include positively relevant words in reviews\n",
    "    summarizer.bonus_words = {\n",
    "        \"best\",\n",
    "        \"excellent\",\n",
    "        \"great\",\n",
    "        \"good\",\n",
    "        \"nice\",\n",
    "        \"perfect\",\n",
    "        \"better\",\n",
    "        \"awesome\",\n",
    "        \"recommend\",\n",
    "        \"super\",\n",
    "        \"fantastic\",\n",
    "        \"exceptional\",\n",
    "        \"outstanding\",\n",
    "    }\n",
    "    # For stigma words, include negatively relevant words in reviews\n",
    "    summarizer.stigma_words = {\n",
    "        \"bad\",\n",
    "        \"worst\",\n",
    "        \"terrible\",\n",
    "        \"poor\",\n",
    "        \"horrible\",\n",
    "        \"disappointing\",\n",
    "        \"avoid\",\n",
    "        \"unfortunately\",\n",
    "        \"cannot\",\n",
    "        \"useless\",\n",
    "        \"problem\",\n",
    "        \"issue\",\n",
    "        \"awful\",\n",
    "    }\n",
    "\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    results = []\n",
    "    # Process each topic file\n",
    "    for topic_file in os.listdir(topics_path):\n",
    "        if not topic_file.endswith(\".txt.data\"):\n",
    "            continue\n",
    "        topic_name = topic_file.replace(\".txt.data\", \"\")\n",
    "        topic_path = os.path.join(topics_path, topic_file)\n",
    "        summaries_dir = os.path.join(summaries_path, topic_name)\n",
    "        if not os.path.exists(summaries_dir):\n",
    "            continue\n",
    "        # Read all reviews\n",
    "        try:\n",
    "            with open(topic_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(topic_path, \"r\", encoding=\"latin-1\") as file:\n",
    "                text = file.read()\n",
    "        # Generate summary\n",
    "        parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))\n",
    "        summary = \" \".join(\n",
    "            str(sentence) for sentence in summarizer(parser.document, SENTENCES_COUNT)\n",
    "        )\n",
    "        # Read and evaluate against gold summaries\n",
    "        summaries_paths = sorted(glob(os.path.join(summaries_dir, \"*.gold\")))\n",
    "        scores_for_topic = []\n",
    "        for gold_path in summaries_paths:\n",
    "            with open(gold_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                gold_summary = f.read()\n",
    "                scores = scorer.score(gold_summary, summary)\n",
    "                scores_for_topic.append(\n",
    "                    {\n",
    "                        \"rouge1\": scores[\"rouge1\"].fmeasure,\n",
    "                        \"rouge2\": scores[\"rouge2\"].fmeasure,\n",
    "                    }\n",
    "                )\n",
    "        # Compute average scores\n",
    "        if scores_for_topic:\n",
    "            avg_rouge1 = sum(score[\"rouge1\"] for score in scores_for_topic) / len(\n",
    "                scores_for_topic\n",
    "            )\n",
    "            avg_rouge2 = sum(score[\"rouge2\"] for score in scores_for_topic) / len(\n",
    "                scores_for_topic\n",
    "            )\n",
    "            results.append({\"rouge1\": avg_rouge1, \"rouge2\": avg_rouge2})\n",
    "    # Compute and output results\n",
    "    if results:\n",
    "        final_rouge1 = sum(result[\"rouge1\"] for result in results) / len(results)\n",
    "        final_rouge2 = sum(result[\"rouge2\"] for result in results) / len(results)\n",
    "        print(\"\\nSumy Edmundson summarizer ROUGE-1, ROUGE-2 scores:\")\n",
    "        print(f\"ROUGE-1: {final_rouge1:.3f}\")\n",
    "        print(f\"ROUGE-2: {final_rouge2:.3f}\")\n",
    "    else:\n",
    "        print(\"No results generated\")\n",
    "\n",
    "\n",
    "print(\"Test the summarizer on Opinosis dataset:\")\n",
    "edmundson_summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58cbcf6",
   "metadata": {},
   "source": [
    "### Task 8: Performance of Topic-Aware Aprroach for Text Summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90855de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract topic keywords\n",
    "def get_topic_keywords(text, structure=None, topic_name=None):\n",
    "    if topic_name:\n",
    "        return [word.lower() for word in topic_name.split()]\n",
    "    elif structure == \"opinosis\":\n",
    "        name = text.replace(\".txt\", \"\").replace(\".data\", \"\")\n",
    "        return [word.lower() for word in name.replace(\"_\", \" \").split()]\n",
    "    else:\n",
    "        # General case, extract 3 text keywords\n",
    "        freq = {}\n",
    "        for token in nlp(text):\n",
    "            if token.is_alpha and not token.is_stop:\n",
    "                key = token.text.lower()\n",
    "                freq[key] = freq.get(key, 0) + 1\n",
    "        if not freq:\n",
    "            return []\n",
    "        sorted_items = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        return [k for k, _ in sorted_items]\n",
    "\n",
    "\n",
    "# Return tf-idf topic relevance scoring\n",
    "def get_topic_relevance(sentences, topic_keywords):\n",
    "    if not sentences or not topic_keywords:\n",
    "        return np.zeros(len(sentences))\n",
    "    corpus = sentences + [\" \".join(topic_keywords)]\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "    topic_vector = tfidf[-1]\n",
    "    sentence_vectors = tfidf[:-1]\n",
    "    relevance = cosine_similarity(sentence_vectors, topic_vector).flatten()\n",
    "    # Normalize to [0,1]\n",
    "    if relevance.max() > 0:\n",
    "        relevance = (relevance - relevance.min()) / relevance.max()\n",
    "    return relevance\n",
    "\n",
    "\n",
    "# Summarize to account for topic of document\n",
    "def summarize_for_topic(text, summarizer, topic_keywords=None):\n",
    "    if topic_keywords is None:\n",
    "        topic_keywords = get_topic_keywords(text)\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))\n",
    "    # Get more summarizer's top sentences (3*3) to include for calculation\n",
    "    base_count = SENTENCES_COUNT * 3\n",
    "    summary_candidates = summarizer(parser.document, base_count)\n",
    "    sentences = [str(sent) for sent in summary_candidates]\n",
    "    # Get relevance to topic for selected sentences\n",
    "    topic_relevance = get_topic_relevance(sentences, topic_keywords)\n",
    "    # Calculate final scores for summarizer's scores times relevance\n",
    "    base_scores = np.linspace(1, 0, len(sentences))\n",
    "    final_scores = base_scores * topic_relevance\n",
    "    # Return selected sentences\n",
    "    top_indices = np.argsort(-final_scores)[:SENTENCES_COUNT]\n",
    "    selected = [sentences[i] for i in sorted(top_indices)]\n",
    "    return \" \".join(selected)\n",
    "\n",
    "\n",
    "def evaluate_opinosis():\n",
    "    results = {name: [] for name in summarizers}\n",
    "    for topic_file in os.listdir(topics_path):\n",
    "        if not topic_file.endswith(\".txt.data\"):\n",
    "            continue\n",
    "        topic_keywords = get_topic_keywords(topic_file, structure=\"opinosis\")\n",
    "        topic_path = os.path.join(topics_path, topic_file)\n",
    "        summaries_dir = os.path.join(\n",
    "            summaries_path, topic_file.replace(\".txt.data\", \"\")\n",
    "        )\n",
    "        if not os.path.exists(summaries_dir):\n",
    "            continue\n",
    "        try:\n",
    "            with open(topic_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(topic_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                text = f.read()\n",
    "        gold_paths = sorted(glob(os.path.join(summaries_dir, \"*.gold\")))\n",
    "        golds = [open(p, \"r\", encoding=\"utf-8\").read() for p in gold_paths]\n",
    "        for name, summarizer in summarizers.items():\n",
    "            summary = summarize_for_topic(text, summarizer, topic_keywords)\n",
    "            scores = [evaluate_rouge(summary, gold) for gold in golds]\n",
    "            avg_scores = {\n",
    "                metric: np.mean([s[metric] for s in scores])\n",
    "                for metric in [\"rouge1\", \"rouge2\"]\n",
    "            }\n",
    "            results[name].append(avg_scores)\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_cnn():\n",
    "    results = {name: [] for name in summarizers}\n",
    "    with open(\"Data/Cnn&Dailymail/low_abstraction.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"Document\\n\"):\n",
    "                doc = next(f).strip()\n",
    "                abstracts = []\n",
    "                while True:\n",
    "                    abstract_line = next(f, None)\n",
    "                    if not abstract_line or abstract_line == \"Document\\n\":\n",
    "                        break\n",
    "                    if abstract_line.startswith(\"Facet-\"):\n",
    "                        abstracts.append(abstract_line.split(\" \", 1)[1].strip())\n",
    "                if abstracts:\n",
    "                    for name, summarizer in summarizers.items():\n",
    "                        summary = summarize_for_topic(doc, summarizer)\n",
    "                        scores = [evaluate_rouge(summary, ab) for ab in abstracts]\n",
    "                        avg_scores = {\n",
    "                            metric: np.mean([s[metric] for s in scores])\n",
    "                            for metric in [\"rouge1\", \"rouge2\"]\n",
    "                        }\n",
    "                        results[name].append(avg_scores)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Initialize summarizers\n",
    "summarizers = {\n",
    "    \"TextRank\": TextRankSummarizer(Stemmer(LANGUAGE)),\n",
    "    \"LSA\": LsaSummarizer(Stemmer(LANGUAGE)),\n",
    "    \"LexRank\": LexRankSummarizer(Stemmer(LANGUAGE)),\n",
    "}\n",
    "for s in summarizers.values():\n",
    "    s.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "\n",
    "# Evaluate on both datasets\n",
    "print(\"\\nTesting summarizaton to account for topic of document on Opinosis dataset:\")\n",
    "opinosis_results = evaluate_opinosis()\n",
    "for name, scores in opinosis_results.items():\n",
    "    avg_r1 = np.mean([s[\"rouge1\"] for s in scores])\n",
    "    avg_r2 = np.mean([s[\"rouge2\"] for s in scores])\n",
    "    print(f\"{name}: ROUGE-1: {avg_r1:.3f}, ROUGE-2: {avg_r2:.3f}\")\n",
    "\n",
    "print(\"\\nTesting summarization to account for topic of document CNN/dailymail dataset:\")\n",
    "cnn_results = evaluate_cnn()\n",
    "for name, scores in cnn_results.items():\n",
    "    avg_r1 = np.mean([s[\"rouge1\"] for s in scores])\n",
    "    avg_r2 = np.mean([s[\"rouge2\"] for s in scores])\n",
    "    print(f\"{name}: ROUGE-1: {avg_r1:.3f}, ROUGE-2: {avg_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff6ea7",
   "metadata": {},
   "source": [
    "### Task 10: Full Text Summarization GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The summarizer GUI will open in a new window and this cell will run as long as the window is open.\n",
    "# Helper function for text summarization\n",
    "def summarize_text(source, is_url=False):\n",
    "    try:\n",
    "        if is_url:\n",
    "            parser = HtmlParser.from_url(source, Tokenizer(LANGUAGE))\n",
    "            text = \" \".join(str(sent) for sent in parser.document.sentences)\n",
    "            opinosis_file = False\n",
    "        else:\n",
    "            # Check for if the file is Opinosis topic file\n",
    "            opinosis_file = (\n",
    "                isinstance(source, str)\n",
    "                and source.endswith(\".txt.data\")\n",
    "                and os.path.exists(source)\n",
    "            )\n",
    "            # Get text from the source file, expect mixed encodings\n",
    "            try:\n",
    "                parser = PlaintextParser.from_file(source, Tokenizer(LANGUAGE))\n",
    "                text = \" \".join(str(sent) for sent in parser.document.sentences)\n",
    "            except Exception:\n",
    "                encodings = (\"utf-8\", \"latin-1\")\n",
    "                content = None\n",
    "                for encoding in encodings:\n",
    "                    try:\n",
    "                        with open(source, \"r\", encoding=encoding) as f:\n",
    "                            content = f.read()\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                if content is None:\n",
    "                    raise\n",
    "                parser = PlaintextParser.from_string(content, Tokenizer(LANGUAGE))\n",
    "                text = \" \".join(str(sent) for sent in parser.document.sentences)\n",
    "\n",
    "        # Initialize summarizers\n",
    "        textrank = TextRankSummarizer(Stemmer(LANGUAGE))\n",
    "        textrank.stop_words = get_stop_words(LANGUAGE)\n",
    "        lsa = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "        lsa.stop_words = get_stop_words(LANGUAGE)\n",
    "        lexrank = LexRankSummarizer(Stemmer(LANGUAGE))\n",
    "        lexrank.stop_words = get_stop_words(LANGUAGE)\n",
    "        edmundson = EdmundsonSummarizer(Stemmer(LANGUAGE))\n",
    "        edmundson.stop_words = get_stop_words(LANGUAGE)\n",
    "        edmundson.null_words = get_stop_words(LANGUAGE)\n",
    "        edmundson.bonus_words = {\n",
    "            \"best\",\n",
    "            \"excellent\",\n",
    "            \"great\",\n",
    "            \"good\",\n",
    "            \"nice\",\n",
    "            \"perfect\",\n",
    "            \"better\",\n",
    "            \"awesome\",\n",
    "            \"recommend\",\n",
    "            \"super\",\n",
    "            \"fantastic\",\n",
    "            \"exceptional\",\n",
    "            \"outstanding\",\n",
    "        }\n",
    "        edmundson.stigma_words = {\n",
    "            \"bad\",\n",
    "            \"worst\",\n",
    "            \"terrible\",\n",
    "            \"poor\",\n",
    "            \"horrible\",\n",
    "            \"disappointing\",\n",
    "            \"avoid\",\n",
    "            \"unfortunately\",\n",
    "            \"cannot\",\n",
    "            \"useless\",\n",
    "            \"problem\",\n",
    "            \"issue\",\n",
    "            \"awful\",\n",
    "        }\n",
    "\n",
    "        # Create summaries dictionary with the summarizer objects\n",
    "        summarizers = {\n",
    "            \"TextRank\": textrank,\n",
    "            \"LSA\": lsa,\n",
    "            \"LexRank\": lexrank,\n",
    "            \"Edmundson\": edmundson,\n",
    "        }\n",
    "\n",
    "        account_topic = topic_var.get()\n",
    "        named_entity = entity_var.get()\n",
    "        summaries = {}\n",
    "\n",
    "        for name, summarizer in summarizers.items():\n",
    "            # Account for topic summarization\n",
    "            if account_topic:\n",
    "                # Extract keywords from filename if Opinosis topic file\n",
    "                if not is_url and opinosis_file:\n",
    "                    filename = os.path.basename(source)\n",
    "                    kw = get_topic_keywords(filename, structure=\"opinosis\")\n",
    "                else:\n",
    "                    # Check if topic name is given\n",
    "                    topic_name = entry_topic.get().strip()\n",
    "                    if topic_name:\n",
    "                        kw = get_topic_keywords(text, topic_name=topic_name)\n",
    "                    else:\n",
    "                        kw = get_topic_keywords(text)\n",
    "                summaries[name] = summarize_for_topic(\n",
    "                    text, summarizer, topic_keywords=kw\n",
    "                )\n",
    "            else:\n",
    "                # Base summarization\n",
    "                base_summary = \" \".join(\n",
    "                    str(s) for s in summarizer(parser.document, SENTENCES_COUNT)\n",
    "                )\n",
    "                if named_entity:\n",
    "                    summaries[name] = add_sents_containing_named_entities(\n",
    "                        base_summary, text, MAX_NEW_SENTENCES\n",
    "                    )\n",
    "                else:\n",
    "                    summaries[name] = base_summary\n",
    "\n",
    "        return summaries\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "        return None\n",
    "\n",
    "\n",
    "# Helper function for browsing a file\n",
    "def browse_file():\n",
    "    filename = filedialog.askopenfilename(\n",
    "        filetypes=[(\"Text files\", \"*.txt *.txt.data\")]\n",
    "    )\n",
    "    entry_source.delete(0, tk.END)\n",
    "    entry_source.insert(0, filename)\n",
    "\n",
    "\n",
    "# Helper function for running summary\n",
    "def run_summary():\n",
    "    source = entry_source.get().strip()\n",
    "    if not source:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter a URL or choose a file\")\n",
    "        return None\n",
    "\n",
    "    is_url = source.startswith(\"http\")\n",
    "    summaries = summarize_text(source, is_url)\n",
    "\n",
    "    if summaries:\n",
    "        # Clear existing summaries\n",
    "        text_textrank.delete(1.0, tk.END)\n",
    "        text_lsa.delete(1.0, tk.END)\n",
    "        text_lexrank.delete(1.0, tk.END)\n",
    "        text_edmundson.delete(1.0, tk.END)\n",
    "\n",
    "        # Insert new summaries\n",
    "        text_textrank.insert(tk.END, summaries[\"TextRank\"])\n",
    "        text_lsa.insert(tk.END, summaries[\"LSA\"])\n",
    "        text_lexrank.insert(tk.END, summaries[\"LexRank\"])\n",
    "        text_edmundson.insert(tk.END, summaries[\"Edmundson\"])\n",
    "\n",
    "\n",
    "# GUI setup using tkinter library\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Summarizer\")\n",
    "root.geometry(\"1200x800\")\n",
    "\n",
    "# Top frame for input\n",
    "frame_top = tk.Frame(root)\n",
    "frame_top.pack(pady=10)\n",
    "\n",
    "tk.Label(\n",
    "    frame_top, text=\"Enter URL or choose a file to get 3 most important sentences:\"\n",
    ").pack(anchor=\"w\", padx=5)\n",
    "entry_source = tk.Entry(frame_top, width=70)\n",
    "entry_source.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "btn_browse = tk.Button(frame_top, text=\"Browse File\", command=browse_file)\n",
    "btn_browse.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "btn_summarize = tk.Button(frame_top, text=\"Summarize\", command=run_summary)\n",
    "btn_summarize.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "# Options frame to include additional methodologies in GUI\n",
    "frame_opts = tk.Frame(root)\n",
    "frame_opts.pack(pady=5)\n",
    "\n",
    "topic_var = tk.BooleanVar()\n",
    "entity_var = tk.BooleanVar()\n",
    "tk.Checkbutton(\n",
    "    frame_opts, text=\"Account for topic of document\", variable=topic_var\n",
    ").pack(side=tk.LEFT)\n",
    "tk.Checkbutton(\n",
    "    frame_opts, text=\"Extend summarization with named-entities\", variable=entity_var\n",
    ").pack(side=tk.LEFT)\n",
    "tk.Label(frame_opts, text=\"(Optional) write topic name:\").pack(side=tk.LEFT, padx=5)\n",
    "entry_topic = tk.Entry(frame_opts, width=30)\n",
    "entry_topic.pack(side=tk.LEFT)\n",
    "\n",
    "# Frame for output text areas\n",
    "frame_texts = tk.Frame(root)\n",
    "frame_texts.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# TextRank output\n",
    "frame_textrank = tk.Frame(frame_texts)\n",
    "frame_textrank.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "tk.Label(frame_textrank, text=\"TextRank Summary:\").pack(anchor=\"n\", pady=5)\n",
    "text_textrank = scrolledtext.ScrolledText(frame_textrank, wrap=tk.WORD, width=30)\n",
    "text_textrank.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# LSA output\n",
    "frame_lsa = tk.Frame(frame_texts)\n",
    "frame_lsa.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "tk.Label(frame_lsa, text=\"LSA Summary:\").pack(anchor=\"n\", pady=5)\n",
    "text_lsa = scrolledtext.ScrolledText(frame_lsa, wrap=tk.WORD, width=30)\n",
    "text_lsa.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# LexRank output\n",
    "frame_lexrank = tk.Frame(frame_texts)\n",
    "frame_lexrank.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "tk.Label(frame_lexrank, text=\"LexRank Summary:\").pack(anchor=\"n\", pady=5)\n",
    "text_lexrank = scrolledtext.ScrolledText(frame_lexrank, wrap=tk.WORD, width=30)\n",
    "text_lexrank.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Edmundson output\n",
    "frame_edmundson = tk.Frame(frame_texts)\n",
    "frame_edmundson.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5)\n",
    "tk.Label(frame_edmundson, text=\"Edmundson Summary:\").pack(anchor=\"n\", pady=5)\n",
    "text_edmundson = scrolledtext.ScrolledText(frame_edmundson, wrap=tk.WORD, width=30)\n",
    "text_edmundson.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "print(\"Text Summarizer GUI is running in a separate window!\")\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
